{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Anime Recommender System on Markdown Notebook**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook outlines the steps taken to build a collaborative and content-based recommender system for a collection of anime titles. The goal is to predict how a user will rate an anime title they have not yet viewed, based on their historical preferences and the characteristics of the anime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Project Motivation and Importance\n",
    "\n",
    "In the age of digital content, recommender systems have become essential tools for personalized content delivery. These systems enhance user experience by suggesting relevant items based on user behavior and item attributes. For anime enthusiasts, discovering new shows that match their tastes can be a delightful experience, and an efficient recommender system can significantly enhance user satisfaction and engagement. \n",
    "\n",
    "Building an anime recommender system can:\n",
    "\n",
    "1. **Improve User Experience**: By suggesting anime titles that align with users' preferences, the system can help users find content they are likely to enjoy, reducing the time spent searching for new shows.\n",
    "2. **Increase Engagement**: Personalized recommendations can increase user interaction and retention, as users are more likely to return to the platform that consistently provides content they like.\n",
    "3. **Drive Business Value**: For platforms hosting anime content, effective recommendation systems can lead to higher user satisfaction, more views, and ultimately, increased revenue.\n",
    "4. **Learn User Preferences**: By analyzing user ratings and behavior, the system can gain insights into trends and preferences, which can be valuable for content creators and distributors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps Covered:\n",
    "1. Data Loading \n",
    "2. Preprocessing\n",
    "3. Exploratory Data Analysis (EDA)\n",
    "4. Model Training\n",
    "5. Model Evaluation\n",
    "6. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Necessary Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "anime_data = pd.read_csv('anime.csv')\n",
    "submission_data=pd.read_csv ('submission.csv')\n",
    "test_data=pd.read_csv ('test.csv')\n",
    "train_data=pd.read_csv ('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11617</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11757</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>15451</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>11771</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  anime_id  rating\n",
       "0        1     11617      10\n",
       "1        1     11757      10\n",
       "2        1     15451      10\n",
       "3        2     11771      10\n",
       "4        3        20       8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Display the first few rows of the anime dataset\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Copies of Original Datasets**\n",
    "\n",
    "To minimize the risk of accidental data loss or irreversible changes during the cleaning operations and process, we create copies of the original datasets.This precaution ensures that the original data remains unchanged and can be referred back to if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.copy(deep=True)\n",
    "test_data = test_data.copy(deep=True)\n",
    "anime_data = test_data.copy(deep=True)\n",
    "submission_data_df = test_data.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2. Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data inspection\n",
    "\n",
    "a summary of essential information about the dataset. It provides metadata and basic statistics that help understand the structure, composition, and characteristics of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12294, 7)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anime Data:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12294 entries, 0 to 12293\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   anime_id  12294 non-null  int64  \n",
      " 1   name      12294 non-null  object \n",
      " 2   genre     12294 non-null  object \n",
      " 3   type      12294 non-null  object \n",
      " 4   episodes  12294 non-null  object \n",
      " 5   rating    12294 non-null  float64\n",
      " 6   members   12294 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 672.5+ KB\n",
      "None\n",
      "\n",
      "Test Data:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 633686 entries, 0 to 633685\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count   Dtype\n",
      "---  ------    --------------   -----\n",
      " 0   user_id   633686 non-null  int64\n",
      " 1   anime_id  633686 non-null  int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 9.7 MB\n",
      "None\n",
      "\n",
      "Train Data:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5703555 entries, 0 to 5703554\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Dtype\n",
      "---  ------    -----\n",
      " 0   user_id   int64\n",
      " 1   anime_id  int64\n",
      " 2   rating    int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 130.5 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Inspect the anime_data\n",
    "print(\"Anime Data:\")\n",
    "print(anime_data.info())\n",
    "\n",
    "# Inspect the test_data\n",
    "print(\"\\nTest Data:\")\n",
    "print(test_data.info())\n",
    "\n",
    "# Inspect the train_data\n",
    "print(\"\\nTrain Data:\")\n",
    "print(train_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.describe of        anime_id                                               name  \\\n",
      "0         32281                                     Kimi no Na wa.   \n",
      "1          5114                   Fullmetal Alchemist: Brotherhood   \n",
      "2         28977                                           GintamaÂ°   \n",
      "3          9253                                        Steins;Gate   \n",
      "4          9969                                      Gintama&#039;   \n",
      "...         ...                                                ...   \n",
      "12289      9316       Toushindai My Lover: Minami tai Mecha-Minami   \n",
      "12290      5543                                        Under World   \n",
      "12291      5621                     Violence Gekiga David no Hoshi   \n",
      "12292      6133  Violence Gekiga Shin David no Hoshi: Inma Dens...   \n",
      "12293     26081                   Yasuji no Pornorama: Yacchimae!!   \n",
      "\n",
      "                                                   genre   type episodes  \\\n",
      "0                   Drama, Romance, School, Supernatural  Movie        1   \n",
      "1      Action, Adventure, Drama, Fantasy, Magic, Mili...     TV       64   \n",
      "2      Action, Comedy, Historical, Parody, Samurai, S...     TV       51   \n",
      "3                                       Sci-Fi, Thriller     TV       24   \n",
      "4      Action, Comedy, Historical, Parody, Samurai, S...     TV       51   \n",
      "...                                                  ...    ...      ...   \n",
      "12289                                             Hentai    OVA        1   \n",
      "12290                                             Hentai    OVA        1   \n",
      "12291                                             Hentai    OVA        4   \n",
      "12292                                             Hentai    OVA        1   \n",
      "12293                                             Hentai  Movie        1   \n",
      "\n",
      "       rating  members  \n",
      "0        9.37   200630  \n",
      "1        9.26   793665  \n",
      "2        9.25   114262  \n",
      "3        9.17   673572  \n",
      "4        9.16   151266  \n",
      "...       ...      ...  \n",
      "12289    4.15      211  \n",
      "12290    4.28      183  \n",
      "12291    4.88      219  \n",
      "12292    4.98      175  \n",
      "12293    5.46      142  \n",
      "\n",
      "[12294 rows x 7 columns]>\n",
      "<bound method NDFrame.describe of         user_id  anime_id\n",
      "0         40763     21405\n",
      "1         68791     10504\n",
      "2         40487      1281\n",
      "3         55290       165\n",
      "4         72323     11111\n",
      "...         ...       ...\n",
      "633681     7345      2768\n",
      "633682    26511      6351\n",
      "633683    18270      2369\n",
      "633684    27989     20507\n",
      "633685    42114      9756\n",
      "\n",
      "[633686 rows x 2 columns]>\n",
      "<bound method NDFrame.describe of          user_id  anime_id  rating\n",
      "0              1     11617      10\n",
      "1              1     11757      10\n",
      "2              1     15451      10\n",
      "3              2     11771      10\n",
      "4              3        20       8\n",
      "...          ...       ...     ...\n",
      "5703550    73515     14345       7\n",
      "5703551    73515     16512       7\n",
      "5703552    73515     17187       9\n",
      "5703553    73515     22145      10\n",
      "5703554    73516      8074       9\n",
      "\n",
      "[5703555 rows x 3 columns]>\n"
     ]
    }
   ],
   "source": [
    "# Get a summary of the dataset\n",
    "print(anime_data.describe)\n",
    "print(test_data.describe)\n",
    "print(train_data.describe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### handling missing values\n",
    "\n",
    "the process of managing or dealing with data points that are absent or undefined in a dataset. Missing values can occur due to various reasons such as data collection errors, data corruption during storage or transmission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in anime_data:\n",
      "anime_id      0\n",
      "name          0\n",
      "genre        62\n",
      "type         25\n",
      "episodes      0\n",
      "rating      230\n",
      "members       0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in test_data:\n",
      "user_id     0\n",
      "anime_id    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in train_data:\n",
      "user_id     0\n",
      "anime_id    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in anime_data\n",
    "print(\"Missing values in anime_data:\")\n",
    "print(anime_data.isnull().sum())\n",
    "\n",
    "# Check for missing values in test_data\n",
    "print(\"\\nMissing values in test_data:\")\n",
    "print(test_data.isnull().sum())\n",
    "\n",
    "# Check for missing values in train_data\n",
    "print(\"\\nMissing values in train_data:\")\n",
    "print(train_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the number of null values present in each column, helping to quickly identify where data is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values count before cleaning:\n",
      "anime_id      0\n",
      "name          0\n",
      "genre        62\n",
      "type         25\n",
      "episodes      0\n",
      "rating      230\n",
      "members       0\n",
      "dtype: int64\n",
      "\n",
      "Null values count after cleaning:\n",
      "anime_id    0\n",
      "name        0\n",
      "genre       0\n",
      "type        0\n",
      "episodes    0\n",
      "rating      0\n",
      "members     0\n",
      "dtype: int64\n",
      "\n",
      "Shape of cleaned dataset: (12017, 7)\n"
     ]
    }
   ],
   "source": [
    "# Display the number of null values before cleaning\n",
    "print(\"Null values count before cleaning:\")\n",
    "print(anime_data.isnull().sum())\n",
    "\n",
    "# Remove rows with any null values\n",
    "anime_data_cleaned = anime_data.dropna()\n",
    "\n",
    "# Display the number of null values after cleaning\n",
    "print(\"\\nNull values count after cleaning:\")\n",
    "print(anime_data_cleaned.isnull().sum())\n",
    "\n",
    "anime_data_cleaned.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print the shape of the cleaned dataset\n",
    "print(f\"\\nShape of cleaned dataset: {anime_data_cleaned.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Duplicates\n",
    "\n",
    "the process of identifying and eliminating identical or redundant entries within a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates in anime_data: 0\n",
      "Duplicates in submission_data: 0\n",
      "Duplicates in test_data: 0\n",
      "Duplicates in train_data: 1\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in anime_data\n",
    "print(\"Duplicates in anime_data:\", anime_data.duplicated().sum())\n",
    "\n",
    "# Check for duplicates in submission_data\n",
    "print(\"Duplicates in submission_data:\", submission_data.duplicated().sum())\n",
    "\n",
    "# Check for duplicates in test_data\n",
    "print(\"Duplicates in test_data:\", test_data.duplicated().sum())\n",
    "\n",
    "# Check for duplicates in train_data\n",
    "print(\"Duplicates in train_data:\", train_data.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed duplicates in train_data\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates in train_data\n",
    "train_data.drop_duplicates(inplace=True)\n",
    "print('removed duplicates in train_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation and Testing\n",
    "\n",
    "verifying the Removal of all rows containing any missing (NaN) values, ensuring that subsequent analyses are based on complete cases without any missing values and duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Null values count after cleaning:\n",
      "anime_id    0\n",
      "name        0\n",
      "genre       0\n",
      "type        0\n",
      "episodes    0\n",
      "rating      0\n",
      "members     0\n",
      "dtype: int64\n",
      "\n",
      "Duplicates count after cleaning: 0\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with any null values\n",
    "anime_data_cleaned = anime_data.dropna()\n",
    "\n",
    "# Display the number of null values after cleaning\n",
    "print(\"\\nNull values count after cleaning:\")\n",
    "print(anime_data_cleaned.isnull().sum())\n",
    "\n",
    "# Verify duplicates removal after cleaning\n",
    "print(f\"\\nDuplicates count after cleaning: {anime_data_cleaned.duplicated().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Categorical Variables\n",
    "\n",
    "Convert the target variable (Category) into numerical labels using Label Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\queen\\AppData\\Local\\Temp\\ipykernel_21680\\3391840069.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(df[column].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Load the dataset\n",
    "anime_data = pd.read_csv('anime.csv')\n",
    "submission_data = pd.read_csv('submission.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "train_data = pd.read_csv('train.csv')\n",
    "\n",
    "# Standardize column names for each dataset\n",
    "def standardize_column_names(df):\n",
    "    df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace(r'[^a-zA-Z0-9_]', '', regex=True)\n",
    "    return df\n",
    "\n",
    "anime_data = standardize_column_names(anime_data)\n",
    "submission_data = standardize_column_names(submission_data)\n",
    "test_data = standardize_column_names(test_data)\n",
    "train_data = standardize_column_names(train_data)\n",
    "\n",
    "# Handling missing values: Fill missing values with mean for numerical columns\n",
    "def fill_missing_values(df):\n",
    "    for column in df.select_dtypes(include=[np.number]).columns:\n",
    "        df[column].fillna(df[column].mean(), inplace=True)\n",
    "    return df\n",
    "\n",
    "anime_data = fill_missing_values(anime_data)\n",
    "submission_data = fill_missing_values(submission_data)\n",
    "test_data = fill_missing_values(test_data)\n",
    "train_data = fill_missing_values(train_data)\n",
    "\n",
    "# Encoding categorical variables using LabelEncoder and OneHotEncoder\n",
    "def encode_categorical_variables(df):\n",
    "    categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "    le = LabelEncoder()\n",
    "    ohe = OneHotEncoder(sparse=False, drop='first')\n",
    "    \n",
    "    for column in categorical_columns:\n",
    "        # Label Encoding\n",
    "        df[column] = le.fit_transform(df[column])\n",
    "        # One-Hot Encoding\n",
    "        encoded_columns = ohe.fit_transform(df[[column]])\n",
    "        encoded_df = pd.DataFrame(encoded_columns, columns=ohe.get_feature_names_out([column]))\n",
    "        df = df.drop([column], axis=1).join(encoded_df)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "transform and prepare the data for it to become more suitable and meaningful for the specific analytical approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   anime_id   name  genre  type  episodes    rating    members\n",
      "0  1.590838   5412   2686     0         0  2.845534   3.330241\n",
      "1 -0.780825   2848    161     5       147  2.737388  14.148406\n",
      "2  1.302401   3346    534     5       132  2.727556   1.754713\n",
      "3 -0.419493  10259   3240     5        84  2.648904  11.957666\n",
      "4 -0.356987   3337    534     5       132  2.639073   2.429742\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Load your dataset\n",
    "anime_data = pd.read_csv('anime.csv')\n",
    "\n",
    "# Handling missing values (filling with median for numerical columns and mode for categorical columns)\n",
    "numerical_cols = anime_data.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols = anime_data.select_dtypes(include=['object']).columns\n",
    "\n",
    "anime_data[numerical_cols] = anime_data[numerical_cols].fillna(anime_data[numerical_cols].median())\n",
    "anime_data[categorical_cols] = anime_data[categorical_cols].fillna(anime_data[categorical_cols].mode().iloc[0])\n",
    "\n",
    "# Encoding categorical variables (Label Encoding)\n",
    "label_encoder = LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "    anime_data[col] = label_encoder.fit_transform(anime_data[col])\n",
    "\n",
    "# Scaling numerical features (Standardization)\n",
    "scaler = StandardScaler()\n",
    "anime_data[numerical_cols] = scaler.fit_transform(anime_data[numerical_cols])\n",
    "\n",
    "# Display the preprocessed dataset\n",
    "print(anime_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### descriptive statistics\n",
    "\n",
    "summarizing and organizing the data to describe the basic features of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types:\n",
      "anime_id      int64\n",
      "name         object\n",
      "genre        object\n",
      "type         object\n",
      "episodes     object\n",
      "rating      float64\n",
      "members       int64\n",
      "dtype: object\n",
      "\n",
      "Descriptive Statistics for Numerical Columns:\n",
      "           anime_id        rating       members\n",
      "count  12294.000000  12064.000000  1.229400e+04\n",
      "mean   14058.221653      6.473902  1.807134e+04\n",
      "std    11455.294701      1.026746  5.482068e+04\n",
      "min        1.000000      1.670000  5.000000e+00\n",
      "25%     3484.250000      5.880000  2.250000e+02\n",
      "50%    10260.500000      6.570000  1.550000e+03\n",
      "75%    24794.500000      7.180000  9.437000e+03\n",
      "max    34527.000000     10.000000  1.013917e+06\n",
      "\n",
      "Descriptive Statistics for Categorical Columns:\n",
      "                           name   genre   type episodes\n",
      "count                     12294   12232  12269    12294\n",
      "unique                    12292    3264      6      187\n",
      "top     Shi Wan Ge Leng Xiaohua  Hentai     TV        1\n",
      "freq                          2     823   3787     5677\n",
      "\n",
      "Unique Value Count for Each Column:\n",
      "anime_id    12294\n",
      "name        12292\n",
      "genre        3264\n",
      "type            6\n",
      "episodes      187\n",
      "rating        598\n",
      "members      6706\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "anime_data = pd.read_csv('anime.csv')\n",
    "\n",
    "# Inspect data types\n",
    "print(\"Data Types:\")\n",
    "print(anime_data.dtypes)\n",
    "\n",
    "# Descriptive statistics for numerical columns\n",
    "print(\"\\nDescriptive Statistics for Numerical Columns:\")\n",
    "print(anime_data.describe())\n",
    "\n",
    "# Descriptive statistics for categorical columns\n",
    "print(\"\\nDescriptive Statistics for Categorical Columns:\")\n",
    "print(anime_data.describe(include=['object']))\n",
    "\n",
    "# Unique value count for each column\n",
    "print(\"\\nUnique Value Count for Each Column:\")\n",
    "print(anime_data.nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types:\n",
      "user_id     int64\n",
      "anime_id    int64\n",
      "dtype: object\n",
      "\n",
      "Descriptive Statistics for Numerical Columns:\n",
      "             user_id       anime_id\n",
      "count  633686.000000  633686.000000\n",
      "mean    36777.752605    8909.389543\n",
      "std     21028.330970    8880.430436\n",
      "min         1.000000       1.000000\n",
      "25%     18974.000000    1240.000000\n",
      "50%     36919.000000    6213.000000\n",
      "75%     54908.000000   14131.000000\n",
      "max     73516.000000   34367.000000\n",
      "\n",
      "Unique Value Count for Each Column:\n",
      "user_id     57053\n",
      "anime_id     7785\n",
      "dtype: int64\n",
      "no descriptive statistics for catagorical columns\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "anime_data = pd.read_csv('test.csv')\n",
    "\n",
    "# Inspect data types\n",
    "print(\"Data Types:\")\n",
    "print(anime_data.dtypes)\n",
    "\n",
    "# Descriptive statistics for numerical columns\n",
    "print(\"\\nDescriptive Statistics for Numerical Columns:\")\n",
    "print(anime_data.describe())\n",
    "\n",
    "\n",
    "# Unique value count for each column\n",
    "print(\"\\nUnique Value Count for Each Column:\")\n",
    "print(anime_data.nunique())\n",
    "\n",
    "print('no descriptive statistics for catagorical columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types:\n",
      "user_id     int64\n",
      "anime_id    int64\n",
      "rating      int64\n",
      "dtype: object\n",
      "\n",
      "Descriptive Statistics for Numerical Columns:\n",
      "            user_id      anime_id        rating\n",
      "count  5.703555e+06  5.703555e+06  5.703555e+06\n",
      "mean   3.674460e+04  8.902142e+03  7.808691e+00\n",
      "std    2.101174e+04  8.882174e+03  1.572449e+00\n",
      "min    1.000000e+00  1.000000e+00  1.000000e+00\n",
      "25%    1.898500e+04  1.239000e+03  7.000000e+00\n",
      "50%    3.680200e+04  6.213000e+03  8.000000e+00\n",
      "75%    5.487300e+04  1.407500e+04  9.000000e+00\n",
      "max    7.351600e+04  3.447500e+04  1.000000e+01\n",
      "\n",
      "Unique Value Count for Each Column:\n",
      "user_id     69481\n",
      "anime_id     9838\n",
      "rating         10\n",
      "dtype: int64\n",
      "no descriptive statistics for catagorical columns\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "anime_data = pd.read_csv('train.csv')\n",
    "\n",
    "# Inspect data types\n",
    "print(\"Data Types:\")\n",
    "print(anime_data.dtypes)\n",
    "\n",
    "# Descriptive statistics for numerical columns\n",
    "print(\"\\nDescriptive Statistics for Numerical Columns:\")\n",
    "print(anime_data.describe())\n",
    "\n",
    "# Unique value count for each column\n",
    "print(\"\\nUnique Value Count for Each Column:\")\n",
    "print(anime_data.nunique())\n",
    "\n",
    "print('no descriptive statistics for catagorical columns')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RecommenderProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
